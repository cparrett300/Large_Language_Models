{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words in Action\n",
    "\n",
    "@author: Aman Kedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\catch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\catch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take in a list of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"We are reading about Natural Language Processing Here\",\n",
    "            \"Natural Language Processing making computers comprehend language data\",\n",
    "            \"The field of Natural Language Processing is evolving everyday\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Pandas Series of the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    We are reading about Natural Language Processi...\n",
       "1    Natural Language Processing making computers c...\n",
       "2    The field of Natural Language Processing is ev...\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.Series(sentences)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(corpus, keep_list):\n",
    "    '''\n",
    "    Purpose : Function to keep only alphabets, digits and certain words (punctuations, qmarks, tabs etc. removed)\n",
    "    \n",
    "    Input : Takes a text corpus, 'corpus' to be cleaned along with a list of words, 'keep_list', which have to be retained\n",
    "            even after the cleaning process\n",
    "    \n",
    "    Output : Returns the cleaned text corpus\n",
    "    \n",
    "    '''\n",
    "    cleaned_corpus = pd.Series()\n",
    "    for row in corpus:\n",
    "        qs = []\n",
    "        for word in row.split():\n",
    "            if word not in keep_list:\n",
    "                p1 = re.sub(pattern='[^a-zA-Z0-9]',repl=' ',string=word)\n",
    "                p1 = p1.lower()\n",
    "                qs.append(p1)\n",
    "            else : qs.append(word)\n",
    "        cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
    "    return cleaned_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_removal(corpus):\n",
    "    wh_words = ['who', 'what', 'when', 'why', 'how', 'which', 'where', 'whom']\n",
    "    stop = set(stopwords.words('english'))\n",
    "    for word in wh_words:\n",
    "        stop.remove(word)\n",
    "    corpus = [[x for x in x.split() if x not in stop] for x in corpus]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(corpus):\n",
    "    lem = WordNetLemmatizer()\n",
    "    corpus = [[lem.lemmatize(x, pos = 'v') for x in x] for x in corpus]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(corpus, stem_type = None):\n",
    "    if stem_type == 'snowball':\n",
    "        stemmer = SnowballStemmer(language = 'english')\n",
    "        corpus = [[stemmer.stem(x) for x in x] for x in corpus]\n",
    "    else :\n",
    "        stemmer = PorterStemmer()\n",
    "        corpus = [[stemmer.stem(x) for x in x] for x in corpus]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(corpus, keep_list, cleaning = True, stemming = False, stem_type = None, lemmatization = False, remove_stopwords = True):\n",
    "    '''\n",
    "    Purpose : Function to perform all pre-processing tasks (cleaning, stemming, lemmatization, stopwords removal etc.)\n",
    "    \n",
    "    Input : \n",
    "    'corpus' - Text corpus on which pre-processing tasks will be performed\n",
    "    'keep_list' - List of words to be retained during cleaning process\n",
    "    'cleaning', 'stemming', 'lemmatization', 'remove_stopwords' - Boolean variables indicating whether a particular task should \n",
    "                                                                  be performed or not\n",
    "    'stem_type' - Choose between Porter stemmer or Snowball(Porter2) stemmer. Default is \"None\", which corresponds to Porter\n",
    "                  Stemmer. 'snowball' corresponds to Snowball Stemmer\n",
    "    \n",
    "    Note : Either stemming or lemmatization should be used. There's no benefit of using both of them together\n",
    "    \n",
    "    Output : Returns the processed text corpus\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if cleaning == True:\n",
    "        corpus = text_clean(corpus, keep_list)\n",
    "    \n",
    "    if remove_stopwords == True:\n",
    "        corpus = stopwords_removal(corpus)\n",
    "    else :\n",
    "        corpus = [[x for x in x.split()] for x in corpus]\n",
    "    \n",
    "    if lemmatization == True:\n",
    "        corpus = lemmatize(corpus)\n",
    "        \n",
    "        \n",
    "    if stemming == True:\n",
    "        corpus = stem(corpus, stem_type)\n",
    "    \n",
    "    corpus = [' '.join(x) for x in corpus]        \n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dot_words = ['U.S.', 'Mr.', 'Mrs.', 'D.C.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\WORKSPACES\\HUGGING FACE\\HANDS ON PYTHON NATURAL LANGUAGE PROCESSING\\Chapter04\\Bag of Words in Action.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/WORKSPACES/HUGGING%20FACE/HANDS%20ON%20PYTHON%20NATURAL%20LANGUAGE%20PROCESSING/Chapter04/Bag%20of%20Words%20in%20Action.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Preprocessing with Lemmatization here\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/WORKSPACES/HUGGING%20FACE/HANDS%20ON%20PYTHON%20NATURAL%20LANGUAGE%20PROCESSING/Chapter04/Bag%20of%20Words%20in%20Action.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m preprocessed_corpus \u001b[39m=\u001b[39m preprocess(corpus, keep_list \u001b[39m=\u001b[39;49m common_dot_words, stemming \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m, stem_type \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/WORKSPACES/HUGGING%20FACE/HANDS%20ON%20PYTHON%20NATURAL%20LANGUAGE%20PROCESSING/Chapter04/Bag%20of%20Words%20in%20Action.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                 lemmatization \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, remove_stopwords \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/WORKSPACES/HUGGING%20FACE/HANDS%20ON%20PYTHON%20NATURAL%20LANGUAGE%20PROCESSING/Chapter04/Bag%20of%20Words%20in%20Action.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m preprocessed_corpus\n",
      "\u001b[1;32md:\\WORKSPACES\\HUGGING FACE\\HANDS ON PYTHON NATURAL LANGUAGE PROCESSING\\Chapter04\\Bag of Words in Action.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/WORKSPACES/HUGGING%20FACE/HANDS%20ON%20PYTHON%20NATURAL%20LANGUAGE%20PROCESSING/Chapter04/Bag%20of%20Words%20in%20Action.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/WORKSPACES/HUGGING%20FACE/HANDS%20ON%20PYTHON%20NATURAL%20LANGUAGE%20PROCESSING/Chapter04/Bag%20of%20Words%20in%20Action.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mPurpose : Function to perform all pre-processing tasks (cleaning, stemming, lemmatization, stopwords removal etc.)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/WORKSPACES/HUGGING%20FACE/HANDS%20ON%20PYTHON%20NATURAL%20LANGUAGE%20PROCESSING/Chapter04/Bag%20of%20Words%20in%20Action.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/WORKSPACES/HUGGING%20FACE/HANDS%20ON%20PYTHON%20NATURAL%20LANGUAGE%20PROCESSING/Chapter04/Bag%20of%20Words%20in%20Action.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/WORKSPACES/HUGGING%20FACE/HANDS%20ON%20PYTHON%20NATURAL%20LANGUAGE%20PROCESSING/Chapter04/Bag%20of%20Words%20in%20Action.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/WORKSPACES/HUGGING%20FACE/HANDS%20ON%20PYTHON%20NATURAL%20LANGUAGE%20PROCESSING/Chapter04/Bag%20of%20Words%20in%20Action.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mif\u001b[39;00m cleaning \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/WORKSPACES/HUGGING%20FACE/HANDS%20ON%20PYTHON%20NATURAL%20LANGUAGE%20PROCESSING/Chapter04/Bag%20of%20Words%20in%20Action.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     corpus \u001b[39m=\u001b[39m text_clean(corpus, keep_list)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/WORKSPACES/HUGGING%20FACE/HANDS%20ON%20PYTHON%20NATURAL%20LANGUAGE%20PROCESSING/Chapter04/Bag%20of%20Words%20in%20Action.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mif\u001b[39;00m remove_stopwords \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/WORKSPACES/HUGGING%20FACE/HANDS%20ON%20PYTHON%20NATURAL%20LANGUAGE%20PROCESSING/Chapter04/Bag%20of%20Words%20in%20Action.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     corpus \u001b[39m=\u001b[39m stopwords_removal(corpus)\n",
      "\u001b[1;32md:\\WORKSPACES\\HUGGING FACE\\HANDS ON PYTHON NATURAL LANGUAGE PROCESSING\\Chapter04\\Bag of Words in Action.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/WORKSPACES/HUGGING%20FACE/HANDS%20ON%20PYTHON%20NATURAL%20LANGUAGE%20PROCESSING/Chapter04/Bag%20of%20Words%20in%20Action.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m             qs\u001b[39m.\u001b[39mappend(p1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/WORKSPACES/HUGGING%20FACE/HANDS%20ON%20PYTHON%20NATURAL%20LANGUAGE%20PROCESSING/Chapter04/Bag%20of%20Words%20in%20Action.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         \u001b[39melse\u001b[39;00m : qs\u001b[39m.\u001b[39mappend(word)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/WORKSPACES/HUGGING%20FACE/HANDS%20ON%20PYTHON%20NATURAL%20LANGUAGE%20PROCESSING/Chapter04/Bag%20of%20Words%20in%20Action.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     cleaned_corpus \u001b[39m=\u001b[39m cleaned_corpus\u001b[39m.\u001b[39;49mappend(pd\u001b[39m.\u001b[39mSeries(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(qs)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/WORKSPACES/HUGGING%20FACE/HANDS%20ON%20PYTHON%20NATURAL%20LANGUAGE%20PROCESSING/Chapter04/Bag%20of%20Words%20in%20Action.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mreturn\u001b[39;00m cleaned_corpus\n",
      "File \u001b[1;32md:\\python_3_11_2\\Lib\\site-packages\\pandas\\core\\generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5982\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5983\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[0;32m   5984\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[0;32m   5985\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[0;32m   5986\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5987\u001b[0m ):\n\u001b[0;32m   5988\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> 5989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "# Preprocessing with Lemmatization here\n",
    "preprocessed_corpus = preprocess(corpus, keep_list = common_dot_words, stemming = False, stem_type = None,\n",
    "                                lemmatization = True, remove_stopwords = True)\n",
    "preprocessed_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\WORKSPACES\\HUGGING FACE\\HANDS ON PYTHON NATURAL LANGUAGE PROCESSING\\Chapter04\\Bag of Words in Action.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/WORKSPACES/HUGGING%20FACE/HANDS%20ON%20PYTHON%20NATURAL%20LANGUAGE%20PROCESSING/Chapter04/Bag%20of%20Words%20in%20Action.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m set_of_words \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/WORKSPACES/HUGGING%20FACE/HANDS%20ON%20PYTHON%20NATURAL%20LANGUAGE%20PROCESSING/Chapter04/Bag%20of%20Words%20in%20Action.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m preprocessed_corpus:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/WORKSPACES/HUGGING%20FACE/HANDS%20ON%20PYTHON%20NATURAL%20LANGUAGE%20PROCESSING/Chapter04/Bag%20of%20Words%20in%20Action.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m sentence\u001b[39m.\u001b[39msplit():\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/WORKSPACES/HUGGING%20FACE/HANDS%20ON%20PYTHON%20NATURAL%20LANGUAGE%20PROCESSING/Chapter04/Bag%20of%20Words%20in%20Action.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         set_of_words\u001b[39m.\u001b[39madd(word)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessed_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "set_of_words = set()\n",
    "for sentence in preprocessed_corpus:\n",
    "    for word in sentence.split():\n",
    "        set_of_words.add(word)\n",
    "vocab = list(set_of_words)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching the position of each word in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computers': 0, 'make': 1, 'read': 2, 'everyday': 3, 'data': 4, 'natural': 5, 'field': 6, 'evolve': 7, 'language': 8, 'process': 9, 'comprehend': 10}\n"
     ]
    }
   ],
   "source": [
    "position = {}\n",
    "for i, token in enumerate(vocab):\n",
    "    position[token] = i\n",
    "print(position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a matrix to hold the Bag of Words representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_matrix = np.zeros((len(preprocessed_corpus), len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, preprocessed_sentence in enumerate(preprocessed_corpus):\n",
    "    for token in preprocessed_sentence.split():   \n",
    "        bow_matrix[i][position[token]] = bow_matrix[i][position[token]] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at our Bag of Words representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0.],\n",
       "       [1., 1., 0., 0., 1., 1., 0., 0., 2., 1., 1.],\n",
       "       [0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Taking example of column 2 in the bow_matrix, the values are 1, 2 and 1 respectively.\n",
    "\n",
    "Column 2 caters to index 2 corresponding to the word *language*.\n",
    "\n",
    "*language* occurs **once, twice and again once** in the the sentences 1, 2 and 3 respectively.\n",
    "\n",
    "Hope that provides you insights into how the Bag of Words model works."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
